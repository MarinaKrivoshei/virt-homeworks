# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя

Необходимо найти операцию с помощью команды db.currentOp()
``` 
db.currentOp({ "active" : true, "secs_running" : { "$gt" : 180 }})
{
    "inprog" : [
        {
            //...
            "opid" : 12345
            //...
        }
    ]
}
```
А затем завершить операцию по opid: db.killOp()

```
db.killOp(12345)
```

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

1.Используя Database Profiler, отловить медленные операции. С помощью executionStats проанализировать. Попробовать
оптимизировать: добавить/удалить индексы, настроить шардинг.

2.Применить метод maxTimeMS() для установки предела исполнения по времени операций. 

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

Есть два механизма удаления истёкших ключей. Первый (lazy) когда к ключу происходит обращение и он оказывается уже истекшим, и второй (active), когда redis сам дропает несколько ключей 10 раз в секунду.
По умолчанию redis сканирует 20 записей за раз (ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)  и если больше 25% просмотренных оказались истёкшими, цикл повторяется.
Но так как цикл запускается 10 раз в секунду, то многие записи могут оказаться истекшими в одну и ту же секунду (например неверное использование EXPIREAT), что приведёт к зацикливанию процесса очистки и блокировки redis до тех пор, пока число истекших записей не снизится до 25%.


 
## Задача 3

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Может произойти из-за того, когда миллионы строк отправляются как часть одного или нескольких запросов. Чтобы решить этот вопрос требуется увеличить net_read_timeout значение по умолчанию с 30 секунд до 60 секунд или дольше, что достаточно для завершения передачи данных.

Или, когда клиент пытается установить первоначальное соединение с сервером. В этом случае, если значение connect_timeout установлено всего на несколько секунд, можно увеличить его до десяти секунд или более.

 Размер сообщения/запроса превышает размер буфера max_allowed_packet на сервере или max_allowed_packet на строне клиента.


Какие пути решения данной проблемы вы можете предложить?

Увеличить параметры описанные выше, можно поочереди, что бы было понятно, какой параметр влияет на возникновение ошибки.

## Задача 4


Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Когда у сервера или процесса заканчивается память, Linux предлагает 2 пути решения: обрушить всю систему или завершить процесс (приложение), который съедает память. Лучше, конечно, завершить процесс и спасти ОС от аварийного завершения. В двух словах, Out-Of-Memory Killer — это процесс, который завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС.

Как бы вы решили данную проблему?

1. По возможности добавить ресурсов (RAM), провести ревизию и отключить/перенести ненужные приложения.
2. Произвести настройку параметров, затрагивающих память в Postgres:
max_connections
shared_buffer
work_mem
effective_cache_size
maintenance_work_mem
3. Так же можно настроить для некоторых процессов OOM-Killer. Linux может зарезервировать для процессов больше памяти, чем есть, но не выделять ее по факту, и этим поведением управляет параметр ядра Linux. За это отвечает переменная vm.overcommit_memory.
Для нее можно указывать следующие значения:
0: ядро само решает, стоит ли резервировать слишком много памяти. Это значение по умолчанию в большинстве версий Linux.
1: ядро всегда будет резервировать лишнюю память. Это рискованно, ведь память может закончиться, потому что, скорее всего, однажды процессы затребуют положенное.
2: ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio.
4. Самый радикальный (не рекомендуемый) способ выключить OOM-Killer в среде выполнения, выполнив команду sysctl с переменной 0

```
sudo -s sysctl -w vm.oom-kill = 0
```
---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
